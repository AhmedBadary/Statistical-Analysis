{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "from math import e\n",
    "from math import log\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sys import maxsize\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, size=40, max_depth = 30, trees=[]):\n",
    "        self.size = size\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "    \n",
    "    def train(self, data, labels):\n",
    "        trees = []\n",
    "        for i in range(self.size):\n",
    "            sub_S = []\n",
    "            sub_L = []\n",
    "            for i in np.random.choice(len(labels), len(labels)):\n",
    "                sub_S.append(data[i])\n",
    "                sub_L.append(labels[i])\n",
    "            sub_S = np.array(sub_S)\n",
    "            sub_L = np.array(sub_L)\n",
    "            clf = DecisionTree(max_depth=self.max_depth, from_tree = True)\n",
    "            clf.train(sub_S, sub_L)\n",
    "            self.trees.append(clf)\n",
    "    def predict(self, X):\n",
    "        p = []\n",
    "        for t in self.trees:\n",
    "            p.append(t.predict(X))\n",
    "        p = np.array(p)\n",
    "        if p.ndim == 1:\n",
    "            p = p.reshape((len(p), 1))\n",
    "        best = []\n",
    "        for i in range(p.shape[1]):\n",
    "            best.append(stats.mode(p[:,i])[0][0])\n",
    "        return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________\n",
    "## \\#\\#\\#FEEL FREE TO IGNORE\\#\\#\\#.\n",
    "## CODE BELOW FOR DECISION TREE CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, split_rule=[0, 0.5], label=None, _type=None, left=None, right=None, height = 0):\n",
    "        self.label = label # mode of the labels of the data_points here\n",
    "        self.split_rule = split_rule\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self._type = None\n",
    "        self.height = height\n",
    "        if label != None:\n",
    "            self._type  = \"leaf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    DECISION TREE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, node = None, max_depth = 40, from_tree = False):\n",
    "        self.node = Node(node)\n",
    "        self.max_depth = max_depth\n",
    "        self.from_tree = from_tree\n",
    "    from operator import itemgetter\n",
    "    def max_val(l, i): # assuming this shit works\n",
    "        return max(enumerate(map(itemgetter(i), l)),key=itemgetter(1))\n",
    "\n",
    "    def train(self, data, labels):\n",
    "        self.node = self.Grow(data, labels, 0)\n",
    "\n",
    "    def Grow(self, data, labels, counter):\n",
    "        d = all_done(labels)  # = [Boolean-if-done, Class-to-choose]\n",
    "        if d[0] == True:\n",
    "            r = d\n",
    "            return Node(label=r[1], height=self.node.height+1)\n",
    "        if counter >= self.max_depth:\n",
    "            return Node(label=stats.mode(labels)[0][0], height=self.node.height+1)\n",
    "        else:\n",
    "            feat = self.segmenter(data, labels) # feat is the index of the feature\n",
    "            if feat == False:\n",
    "                return Node(label=stats.mode(labels)[0][0], height=self.node.height+1)\n",
    "            split_val = feat[1] # split_val is the value to split on\n",
    "            feat = feat[0]\n",
    "            dd = np.append(data, labels.reshape((len(labels),1)), 1)\n",
    "            dd = dd[dd[:,feat].argsort()]\n",
    "            if split_val == 0.5 or split_val == 0:\n",
    "                if len(dd[:,feat]) <= 2:\n",
    "                    sp = 1\n",
    "                else:\n",
    "                    sp = 1\n",
    "            else:\n",
    "                sp = dd[:,feat].tolist().index(split_val)\n",
    "            Sl = [dd[x] for x in range(sp)]\n",
    "            Sr = [dd[x] for x in range(sp, len(dd))]\n",
    "            return Node(split_rule=[feat,split_val],\n",
    "                        left=self.Grow(np.array(Sl)[:,:-1],np.array(Sl)[:,-1], counter+1),\n",
    "                        right=self.Grow(np.array(Sr)[:,:-1],np.array(Sr)[:,-1], counter+1), height=self.node.height+1)\n",
    "\n",
    "    def predict(self, data):\n",
    "        j = []\n",
    "        if type(data[0]) == np.ndarray:\n",
    "            for i in data:\n",
    "                n = self.node\n",
    "                while n._type is None:\n",
    "                    rule_f = n.split_rule[0]\n",
    "                    rule_v = n.split_rule[1]\n",
    "                    if i[rule_f] < rule_v:\n",
    "                        n = n.left\n",
    "                    else:\n",
    "                        n = n.right\n",
    "                j.append(n.label)\n",
    "            return j\n",
    "        else:\n",
    "            n = self.node\n",
    "            while n._type is None:\n",
    "                    rule_f = n.split_rule[0]\n",
    "                    rule_v = n.split_rule[1]\n",
    "                    print(\"feat = \", rule_f, \" , \", \"split_val = \", rule_v)\n",
    "                    if data[rule_f] < rule_v:\n",
    "                        print(\"LEFT\")\n",
    "                        n = n.left\n",
    "                    else:\n",
    "                        print(\"RIGHT\")\n",
    "                        n = n.right\n",
    "        return n.label\n",
    "    \n",
    "    def segmenter(self, data, labels):\n",
    "        off, best_feature, best_in_feature, num_features = [], [], [], data.shape[1]\n",
    "        same = 0\n",
    "        t = [i for i in range(len(data))]\n",
    "        if self.from_tree == True:\n",
    "            off = np.random.choice((data.shape[1]-1), data.shape[1]-int(np.sqrt((data.shape[1]-1))) , replace=False)\n",
    "        ent = entropy(t, labels)\n",
    "        for i in range(num_features): # features\n",
    "            if i in off:\n",
    "                continue\n",
    "            features = _get_features(data[:,i])\n",
    "            hist = []\n",
    "            if len(features) <= 2:\n",
    "                for f in features:\n",
    "                    for j in range(len(data)):\n",
    "                        if data[j][i] == f:\n",
    "                            features[f].append(j)\n",
    "                    hist.append(features[f])\n",
    "                if len(features) <= 1:\n",
    "                    same+=1\n",
    "                    best_feature.append((i, 0.5, ent - ent))\n",
    "                else:\n",
    "                    best_feature.append((i, 0.5, ent - impurity(hist[0], hist[1], labels)))\n",
    "            else:\n",
    "                _xs = len([u for u in labels if u == 0])\n",
    "                _os = len(labels) - _xs\n",
    "                fs, best_in_feature, best_in_feature = [], [], np.append(data, labels.reshape((len(labels),1)), 1)\n",
    "                dd = dd[dd[:,i].argsort()]\n",
    "                old = dd[0][i]\n",
    "                count, __xs, __os = 0\n",
    "                fs.append(old)\n",
    "                for pt in dd:\n",
    "                    if old == pt[i]:\n",
    "                        if pt[-1] == 0:\n",
    "                            _xs -= 1\n",
    "                            __xs += 1\n",
    "                        else:\n",
    "                            _os -= 1\n",
    "                            __os += 1\n",
    "                    else:\n",
    "                        best_in_feature.append(ent - man_weighted_av_entr(__xs,__os,_xs,_os))\n",
    "                        fs.append(pt[i])\n",
    "                        if pt[-1] == 0:\n",
    "                            _xs -= 1\n",
    "                            __xs += 1\n",
    "                        else:\n",
    "                            _os -= 1\n",
    "                            __os += 1\n",
    "                ind = best_in_feature.index(max(best_in_feature))\n",
    "                if ind + 1 != len(best_in_feature):\n",
    "                    ind += 1\n",
    "                    best_feature.append((i, fs[ind], best_in_feature[ind - 1]))\n",
    "                else:\n",
    "                    best_feature.append((i, fs[ind], best_in_feature[ind]))\n",
    "        if same == num_features-1:\n",
    "            return False\n",
    "        m = max_val(best_feature, -1)\n",
    "        return (best_feature[m[0]][0], best_feature[m[0]][1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
