{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "from math import e\n",
    "from math import log\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sys import maxsize\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, split_rule=[0, 0.5], label=None, _type=None, left=None, right=None, height = 0):\n",
    "        self.label = label # mode of the labels of the data_points here\n",
    "        self.split_rule = split_rule\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self._type = None\n",
    "        self.height = height\n",
    "        if label != None:\n",
    "            self._type  = \"leaf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    DECISION TREE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, node = None, max_depth = 40, from_tree = False):\n",
    "        self.node = Node(node)\n",
    "        self.max_depth = max_depth\n",
    "        self.from_tree = from_tree\n",
    "    from operator import itemgetter\n",
    "    def max_val(l, i): # assuming this shit works\n",
    "        return max(enumerate(map(itemgetter(i), l)),key=itemgetter(1))\n",
    "\n",
    "    def train(self, data, labels):\n",
    "        self.node = self.Grow(data, labels, 0)\n",
    "\n",
    "    def Grow(self, data, labels, counter):\n",
    "        d = all_done(labels)  # = [Boolean-if-done, Class-to-choose]\n",
    "        if d[0] == True:\n",
    "            r = d\n",
    "            return Node(label=r[1], height=self.node.height+1)\n",
    "        if counter >= self.max_depth:\n",
    "            return Node(label=stats.mode(labels)[0][0], height=self.node.height+1)\n",
    "        else:\n",
    "            feat = self.segmenter(data, labels) # feat is the index of the feature\n",
    "            if feat == False:\n",
    "                return Node(label=stats.mode(labels)[0][0], height=self.node.height+1)\n",
    "            split_val = feat[1] # split_val is the value to split on\n",
    "            feat = feat[0]\n",
    "            dd = np.append(data, labels.reshape((len(labels),1)), 1)\n",
    "            dd = dd[dd[:,feat].argsort()]\n",
    "            if split_val == 0.5 or split_val == 0:\n",
    "                if len(dd[:,feat]) <= 2:\n",
    "                    sp = 1\n",
    "                else:\n",
    "                    sp = 1\n",
    "            else:\n",
    "                sp = dd[:,feat].tolist().index(split_val)\n",
    "            Sl = [dd[x] for x in range(sp)]\n",
    "            Sr = [dd[x] for x in range(sp, len(dd))]\n",
    "            return Node(split_rule=[feat,split_val],\n",
    "                        left=self.Grow(np.array(Sl)[:,:-1],np.array(Sl)[:,-1], counter+1),\n",
    "                        right=self.Grow(np.array(Sr)[:,:-1],np.array(Sr)[:,-1], counter+1), height=self.node.height+1)\n",
    "\n",
    "    def predict(self, data):\n",
    "        j = []\n",
    "        if type(data[0]) == np.ndarray:\n",
    "            for i in data:\n",
    "                n = self.node\n",
    "                while n._type is None:\n",
    "                    rule_f = n.split_rule[0]\n",
    "                    rule_v = n.split_rule[1]\n",
    "                    if i[rule_f] < rule_v:\n",
    "                        n = n.left\n",
    "                    else:\n",
    "                        n = n.right\n",
    "                j.append(n.label)\n",
    "            return j\n",
    "        else:\n",
    "            n = self.node\n",
    "            while n._type is None:\n",
    "                    rule_f = n.split_rule[0]\n",
    "                    rule_v = n.split_rule[1]\n",
    "                    print(\"feat = \", rule_f, \" , \", \"split_val = \", rule_v)\n",
    "                    if data[rule_f] < rule_v:\n",
    "                        print(\"LEFT\")\n",
    "                        n = n.left\n",
    "                    else:\n",
    "                        print(\"RIGHT\")\n",
    "                        n = n.right\n",
    "        return n.label\n",
    "    \n",
    "    def segmenter(self, data, labels):\n",
    "        off, best_feature, best_in_feature, num_features = [], [], [], data.shape[1]\n",
    "        same = 0\n",
    "        t = [i for i in range(len(data))]\n",
    "        if self.from_tree == True:\n",
    "            off = np.random.choice((data.shape[1]-1), data.shape[1]-int(np.sqrt((data.shape[1]-1))) , replace=False)\n",
    "        ent = entropy(t, labels)\n",
    "        for i in range(num_features): # features\n",
    "            if i in off:\n",
    "                continue\n",
    "            features = _get_features(data[:,i])\n",
    "            hist = []\n",
    "            if len(features) <= 2:\n",
    "                for f in features:\n",
    "                    for j in range(len(data)):\n",
    "                        if data[j][i] == f:\n",
    "                            features[f].append(j)\n",
    "                    hist.append(features[f])\n",
    "                if len(features) <= 1:\n",
    "                    same+=1\n",
    "                    best_feature.append((i, 0.5, ent - ent))\n",
    "                else:\n",
    "                    best_feature.append((i, 0.5, ent - impurity(hist[0], hist[1], labels)))\n",
    "            else:\n",
    "                _xs = len([u for u in labels if u == 0])\n",
    "                _os = len(labels) - _xs\n",
    "                fs, best_in_feature, best_in_feature = [], [], np.append(data, labels.reshape((len(labels),1)), 1)\n",
    "                dd = dd[dd[:,i].argsort()]\n",
    "                old = dd[0][i]\n",
    "                count, __xs, __os = 0\n",
    "                fs.append(old)\n",
    "                for pt in dd:\n",
    "                    if old == pt[i]:\n",
    "                        if pt[-1] == 0:\n",
    "                            _xs -= 1\n",
    "                            __xs += 1\n",
    "                        else:\n",
    "                            _os -= 1\n",
    "                            __os += 1\n",
    "                    else:\n",
    "                        best_in_feature.append(ent - man_weighted_av_entr(__xs,__os,_xs,_os))\n",
    "                        fs.append(pt[i])\n",
    "                        if pt[-1] == 0:\n",
    "                            _xs -= 1\n",
    "                            __xs += 1\n",
    "                        else:\n",
    "                            _os -= 1\n",
    "                            __os += 1\n",
    "                ind = best_in_feature.index(max(best_in_feature))\n",
    "                if ind + 1 != len(best_in_feature):\n",
    "                    ind += 1\n",
    "                    best_feature.append((i, fs[ind], best_in_feature[ind - 1]))\n",
    "                else:\n",
    "                    best_feature.append((i, fs[ind], best_in_feature[ind]))\n",
    "        if same == num_features-1:\n",
    "            return False\n",
    "        m = max_val(best_feature, -1)\n",
    "        return (best_feature[m[0]][0], best_feature[m[0]][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labels(X, f):\n",
    "    l = []\n",
    "    for i in X:\n",
    "        if i in l:\n",
    "            continue\n",
    "        if i == f:\n",
    "            l.append(i)\n",
    "    if l != []:\n",
    "        return l\n",
    "\n",
    "def get_features(X, _all):\n",
    "    l = [0 for i in range(len(_all))]\n",
    "    m = dict(zip(_all, l))\n",
    "    for lbl in _all:\n",
    "        o = get_labels(X, lbl)\n",
    "        if o == None:\n",
    "            continue\n",
    "        m[lbl] = o\n",
    "    return m\n",
    "\n",
    "log_2 = lambda x: float(log(x)) / log(2)\n",
    "\n",
    "def entropy(S, labels):\n",
    "    var = 0\n",
    "    Pc = []\n",
    "    j = 0\n",
    "    if len(S) == 0:\n",
    "        return 0\n",
    "    for i in S:\n",
    "        if labels[i] == 0:\n",
    "            Pc.append(i)\n",
    "    Pc = float(len(Pc)) / len(S)\n",
    "    if Pc == 0:\n",
    "        return 0\n",
    "    lg = log_2(Pc)\n",
    "    var -= Pc*lg\n",
    "\n",
    "    Pd = 1 - Pc\n",
    "    if Pd == 0:\n",
    "        return 0\n",
    "    lg = log_2(Pd)\n",
    "    var -= Pd*lg\n",
    "    return (var)\n",
    "\n",
    "def weighted_av_entr(Sl, Sr, labels):\n",
    "    H_Sl = entropy(Sl, labels)\n",
    "    H_Sr = entropy(Sr, labels)\n",
    "    top = len(Sl) * H_Sl + len(Sr) * H_Sr\n",
    "    down = len(Sl) + len(Sr)\n",
    "    return top / down\n",
    "\n",
    "def mode(l):\n",
    "    z, o = 0\n",
    "    for i in l:\n",
    "        if i == 0:\n",
    "            z+=1\n",
    "        else:\n",
    "            o+=1\n",
    "    if z > 0:\n",
    "        return 0\n",
    "    return 1\n",
    "    \n",
    "def man_entropy(x, o):\n",
    "    var = 0\n",
    "    if (x + o) == 0:\n",
    "        return - 1\n",
    "    Pc = float(x) / (x+o)\n",
    "    if Pc == 0:\n",
    "        return 0\n",
    "    lg = log_2(Pc)\n",
    "    var -= Pc*lg\n",
    "\n",
    "    Pd = 1 - Pc\n",
    "    if Pd == 0:\n",
    "        return 0\n",
    "    lg = log_2(Pd)\n",
    "    var -= Pd*lg\n",
    "    return var\n",
    "\n",
    "def man_weighted_av_entr(__x, __o, _x, _o):\n",
    "    H_Sl = man_entropy(__x, __o)\n",
    "    H_Sr = man_entropy(_x, _o)\n",
    "    top = (__x+__o) * H_Sl + (_x+_o) * H_Sr\n",
    "    down = (__x+__o) + (_x+_o)\n",
    "    return float(top) / down\n",
    "\n",
    "def _get_features(X):\n",
    "    l = []\n",
    "    for i in X:\n",
    "        if i in l:\n",
    "            continue\n",
    "        else:\n",
    "            l.append(i)\n",
    "    r = [[] for i in range(len(l))]\n",
    "    m = dict(zip(l, r))\n",
    "    return m\n",
    "\n",
    "from operator import itemgetter\n",
    "def max_val(l, i):\n",
    "    return max(enumerate(map(itemgetter(i), l)),key=itemgetter(1))\n",
    "\n",
    "def all_done(y):\n",
    "    s = sum(y)\n",
    "    if s == len(y):\n",
    "        return (True, 1)\n",
    "    if s == 0:\n",
    "        return (True, 0)\n",
    "    return (False, \"fuck\")\n",
    "\n",
    "def impurity(left_label_hist, right_label_hist, labels):\n",
    "    classes  = [0,1]\n",
    "    return weighted_av_entr(left_label_hist, right_label_hist, labels)\n",
    "\n",
    "def test_clf(pred, orig):\n",
    "    m = []\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == orig[i]:\n",
    "            m.append(1)\n",
    "    res = len(m)/len(pred)\n",
    "    if res > 0.72:\n",
    "        print(\"SUCESS!!!\")\n",
    "    else:\n",
    "        print(\"Failure....\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
